---
title: 'Project 2: Data Mining, Classification, Prediction'
author: "SDS322E"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))

class_diag <- function(score, truth, positive, cutoff=.5){

  pred <- factor(score>cutoff,levels=c("TRUE","FALSE"))
  truth <- factor(truth==positive, levels=c("TRUE","FALSE"))

  tab<-table(truth, pred)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[1,1]/rowSums(tab)[1]
  spec=tab[2,2]/rowSums(tab)[2]
  ppv=tab[1,1]/colSums(tab)[1]

#CALCULATE F1
  f1=2*(sens*ppv)/(sens+ppv)
  
#CALCULATE EXACT AUC
  truth<-as.numeric(truth=="TRUE")
  ord<-order(score, decreasing=TRUE)
  score <- score[ord]; truth <- truth[ord]
  TPR=cumsum(truth)/max(1,sum(truth))
  FPR=cumsum(!truth)/max(1,sum(!truth))
  dup<-c(score[-1]>=score[-length(score)], FALSE)
  TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
  n <- length(TPR)
  auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
  round(data.frame(acc,sens,spec,ppv,f1,ba=(sens+spec)/2,auc, row.names = "Metrics"),4)
}
```

# Mining, Classification, Prediction

## Name and EID here Chengmin Xu, cx2546

### Introduction 

Paragraph or two introducing your datasets and variables, why they are interesting to you, etc. See instructions for more information

Introduction:
Graduation is approaching, one of the most important things come to my mind is job. Getting a good job and earning good salary are dreams for everyone. But, what factors actually affect wage? Does education really matter? What about IQ and other factors? These questions rouse my interest in exploring the relationship between wage and these factors by using data software(e.g. R-Studio and Python) to analyze.  

The data set we use in this project is the publicly available data from a research of my major.It is a survey over 200 adults and contains 13 variables.The main variables include "wage"( monthly earnings), "hour"(average weekly hours),"IQ"(IQ score), "exper"(years of work experience),"age"(age in years), "married"(=1 if married), "black"(=1 if black), "urtban"(=1 if live in SMSA)etc.There are 24 observations for unmarried people, and 176 observations for married people;165 observations for non-black people, and 35 observations for black people.

```{R}
library(tidyverse)
# read your datasets in here, e.g., with read_csv()
data_wage <- read_csv("new.csv")

```

### Cluster Analysis

```{R}
library(cluster)
# clustering code here
wage_pam <- data_wage%>%pam(k=3)
pamclust<-data_wage %>% mutate(cluster = as.factor(wage_pam$clustering))
pamclust%>%ggplot(aes(KWW, wage, shape=cluster, color=black))+geom_point()

pamclust<-data_wage %>% mutate(cluster = as.factor(wage_pam$clustering))
pamclust%>%ggplot(aes(educ, wage, shape=cluster, color=urban))+geom_point()

pamclust<-data_wage %>% mutate(cluster = as.factor(wage_pam$clustering))
pamclust%>%ggplot(aes(IQ, wage, shape=cluster, color=married))+geom_point()

sil_width <- vector()
for (i in 2:10) {
    pam_fit <- pam(data_wage, k = i)
    sil_width[i] <- pam_fit$silinfo$avg.width
}
ggplot() + geom_line(aes(x = 1:10, y = sil_width)) + 
    scale_x_continuous(name = "k", breaks = 1:10)

wage_pam <- data_wage%>%pam(k=3)
plot(wage_pam)

data_wage%>% slice(wage_pam$id.med)


library(GGally)
data_wage %>% mutate(cluster = as.factor(wage_pam$clustering)) %>% 
    ggpairs(columns =2:9, aes(color = cluster))

```

Discussion of clustering here
    
    
### Dimensionality Reduction with PCA

```{R}
# PCA code here
data_wage2<-data_wage %>% select(-1,-10,-11,-12,-13)
pca_data_wage2 <- princomp(data_wage2, cor = T)
names(pca_data_wage2)
summary(pca_data_wage2, loadings=T)

eigval <-pca_data_wage2$sdev^2
varprop=round(eigval/sum(eigval), 2)
  
ggplot() + geom_bar(aes(y=varprop, x=1:8), stat="identity") + xlab("") + geom_path(aes(y=varprop, x=1:8))+
geom_text(aes(x=1:8, y=varprop, label=round(varprop, 2)), vjust=1, col="white", size=5)+
scale_y_continuous(breaks=seq(0, .6, .2), labels = scales::percent) +
scale_x_continuous(breaks=1:10)

round(cumsum(eigval)/sum(eigval), 2)

data_wage2 %>% mutate(PC1=pca_data_wage2$scores[, 1], PC2=pca_data_wage2$scores[, 2]) %>%
ggplot(aes(PC1, PC2, color=data_wage$married)) + geom_point() + coord_fixed()

library(factoextra)
fviz_pca_biplot(pca_data_wage2)
fviz_pca_biplot(pca_data_wage2, col.ind = data_wage$married, ) + coord_fixed()
fviz_pca_biplot(pca_data_wage2, col.ind = data_wage$black, ) + coord_fixed()
fviz_pca_biplot(pca_data_wage2, col.ind = data_wage$urban, ) + coord_fixed()

```

Discussions of PCA here. 

###  Linear Classifier

```{R}
# linear classifier code here
```

```{R}
# cross-validation of linear classifier here
```

Discussion here

### Non-Parametric Classifier

```{R}
library(caret)
# non-parametric classifier code here
```

```{R}
# cross-validation of np classifier here
```

Discussion


### Regression/Numeric Prediction

```{R}
# regression model code here
```

```{R}
# cross-validation of regression model here
```

Discussion

### Python 

```{R}
library(reticulate)
```

```{python}
# python code here
```

Discussion

### Concluding Remarks

Include concluding remarks here, if any




